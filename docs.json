[
  {
    "name": "WWDCSessionNotesHerman",
    "body": "Terugkijken:\n============\n\n-   SwiftUI on all devices\n-   Developing a Great Profiling Experience\n-   Adding Indoor Maps to your App and Website\n\nUitzoeken:\n\n-   CallKit Identity Lookup, vet voor Q42 als collega belt zonder dat je\n    \\'t nummer hebt?\n\nDay 2, session 1, Accessibility\n===============================\n\n-   \"Button\" is spoken after accessibilityLabel\n-   Cookie Monster emoji app voorbeeld: \"Me happy face eat small cookie,\n    om nom nom\"\n-   Accessibility Custom Actions\n-   Needed for 1) Reducing clutter 2) Convenience & speed\n-   Disable repeated buttons in a table view & replace with actions\n-   Speaks \"actions available\", swipe up to read the actions\n-   Primephonic: \"play\" / \"add to playlist\" / etc\n-   \"control.isAccessibilityElement = false\"\n-   \"control.accessibilityCustomActions\"\n-   Improvements\n-   Accessibility \"Environment overrides\" panel to quickly switch\n    simulator to accessibility settings\n-   UIAccessibility.isReduceMotionEnabled: Bool\n-   Color-Blindness, \"Differentiate without Colour\" so you can switch\n    from using colours to switching to icons.\n-   Accessibility Inspector\n-   Xcode \\> Open Developer Tool \\> Accessibility Inspector\n-   Options: Audit, Inspect, Environment Settings\n-   No need to globally enable Voice-Over in Simulator: Voice-Over\n    controls are available in the tool.\n-   Color Contrast calculator\n-   Windows \\> Show Color Contrast Calculator\n\nMore:\n\n-   [https://npr.codes/custom-accessibility-actions-for-ios-3e35409c9dcc](https://www.google.com/url?q=https://npr.codes/custom-accessibility-actions-for-ios-3e35409c9dcc&sa=D&ust=1559981348835000)\n-   Accessibility Inspector existed before and was already used for Mac\n    apps\n\nDay 2, session 2, What\\'s new in Swift\n======================================\n\nTed Kremenek, Anna Zaks\n\n-   swiftmodule =\\> swiftinterface\n-   Shared runtime for compatible OS'ses. App Store thins the runtime\n    copy away if the bundle is build for older OS'ses too.\n-   10% smaller code size with Swift 5.1 due to optimizations\n-   15x faster String -\\> NSString bridging between Objective-C/Swift\n    due to using UTF-8 instead of UTF-16\n-   Dockerized Swift available on DockerHub\n-   soucekitd stress tests\n-   LSP: apple/sourcekit-lsp for source code completions in\n    vim/vscode/etc.\n-   String interpolation with \"LocalizedStringKey\": translation AFTER\n    the translation is done. SE-0228\n-   Opaque Result Types: \"some Shape\"\n\n<!-- -->\n\n-   Mitigates 4 downsides of returning the root Protocol type\n-   Equality checks\n-   Compiler optimizations, etc.\n\n<!-- -->\n\n-   \\@propertyWrapper to declare & access\n-   Embedded DSLs: this drives HTML DSL & SwiftUI framework\n\n<!-- -->\n\n-   https://forums.swift.org/t/pitch-function-builders/25167\n\nDay 2, session 3, Desktop Class browsing on iPad\n================================================\n\n-   Regular shotcuts in Safari\n-   iPad presents itself as a Mac instead of an iOS device!\n-   Pointer events\n-   WebViews in Apps\n\n<!-- -->\n\n-   Link following\n-   Web browser\n-   Hybrid app\n-   Authentication\n\n<!-- -->\n\n-   SFViewController gets MacOS instead of iOS agent / class\n-   Automatically specifies correct browsing mode (split screen/iPad\n    mini)\n-   webkit.applicationNameForUserAgent : fills in the rest auto\n-   WKWebPagePreferences.ContentMode { desktop, mobile, auto }\n-   decidePolicyFor navigation\n\n------------------\n\n-   For app developers\n-   webView.customUserAgent =\\> WKWebViewConfiguration with\n    applicationNameForUserAgent\n-   Delegate didCommit navigation: WKNavigaton.effectiveContentMode can\n    be used to read the actually used ContentMode\n\n---------------\n\n-   For web developers, by Beth Dakin\n-   window.PointerEvent feature detection\n-   Event type: \"pointermove\" (or else \"mousemove\")\n-   PointerEvent.eventType = \\[ pen, mouse, touch \\]\n-   CSS \"touch-action: none;\" to click instead of touch-scroll\n-   On hover, if a meaning full HTML/style change happens, the click is\n    not performed: a heuristic to support hover\n-   Hardware Accelerated Scrolling for iframes/subframes!!!\n-   \\`-webkit-overflow-scrolling: touch;\\` & TouchEvents are not\n    required anymore.\n-   \\`-webkit-overflow-scrolling: touch;\\` is now a noop on iPad.\n-   \"viewport\" misuse, so now iPadOS will ignore viewport if the HTML is\n    wider than the device-width. Will shrink view & upscale the text.\n-   So implement responsive design correctly, or you will be shrunk\n-   window.visualViewport, addEventListener(\"visualViewportChange\") to\n    detect Keyboard overlapping the content\n-   matchMedia(\"(hover: hover)\") om in JavaScript media queries te\n    runnen (is al oud?)\n\nDay 2, session 4, iPad apps for Mac\n===================================\n\nAli ozer, Jake petroules, Jason beaver\n\n-   xcframework for multi-platform bundles & works for Objective-C too\n\nDay 2, session 6, Reality Kit\n=============================\n\n-   Build on top of Mesh Networking for shared world model\n-   ARView, Achor, Scene & Entity\n-   Control the Depth of Field on basic of the iPhone Camera\n-   Filmgrain: addable for more realistic blend\n\nDay 3, session 3, SwiftUI Essentials\n====================================\n\n-   Views are nice, but how do you: cloud sync, drag & drop\n-   Bindings, \\@State attribute, \"Data Flow through Swift UI\", Thursday\n    9:00\n-   Forms, like VStack but for heterogeneous views\n-   VStack =\\> Form, is a drop-in replacement\n-   Section { ... } for grouping\n-   Parent view customizes subview properties\n\nSwiftUI Labs\n============\n\n-   UITableView like performance will come in future releases, the\n    current List is less performant.\n-   Data Bindings how-to\n    (https://gist.github.com/hermanbanken/ea65fedf16ad8eac75c3dacfe6de4663)\n-   [https://twitter.com/hermanbanken/status/1136371582656425986](https://www.google.com/url?q=https://twitter.com/hermanbanken/status/1136371582656425986&sa=D&ust=1559981348845000)\n-   UITableView prefetching using .OnAppear and .OnDisappear\n\nDay 3, session 2, Understanding Images in Visual Framework\n==========================================================\n\n-   More face-landmarks\n-   Demo with SimilarityGame: draw image & let others replicate it,\n    winner is closed match\n\nDay 3, session 4, Apple Watch SwiftUI\n=====================================\n\n-   WKHostingController\\<ViewType\\>\n-   Rich notifications are made of Short View (Logo & App naam) and Long\n    View: detail\n-   Long View is the main interface of your app on the watch\n-   Pinnen of View Previews in XCode, so you can view 2 views at the\n    same time while editing (view the parent view while updating the\n    child)\n-   List, Picker, ScrollView all give Crown integratie & Haptic feedback\n-   Modifier \\`.digitalCrownRotation(binding: destinationProp, from:\n    1.0, through: 15.0, by: 2.0)\\`\n-   And also: \\`.digitalCrownRotation(binding: destinationProp, from:\n    1.0, through: 15.0, by: 2.0, sensitivity: .low, isContinuous:\n    true)\\`\n-   Modifier \\`.focusable(true)\\`\n-   ZStack, next to V-/HStack\n-   See other talk \"SwiftUI on all devices\", Friday\n-   Code available with WWDC Video\n\nDay 3, session 5, Swift Package Manager\n=======================================\n\n-   Using package\n-   What is a package\n-   Package resolution\n-   Updating package\n\nDay 3, session 7, Designing Audio-Haptic Experiences\n====================================================\n\n-   Hugo Verweij & Camille ...\n-   Haptics zijn low frequency sounds\n-   Haptic sharpness is de vorm van de buik van de 'golf'\n-   Causality, Harmony, Utility\n\nDay 4, session 1, Data Flows through SwiftUI\n============================================\n\n-   Luca Benardi, Raj Ramamurthy\n-   Principles of Data Flow\n-   Anatomy of an Update\n-   Understanding Your Data\n\n-   Property, BindableObject, \\@Environment, \\@Binding, \\@State\n-   \"\\@State is the source of truth\"\n-   \"Views are a function of state, not of a sequence of events\"\n-   \\$-prefix derives a \\@Binding from a \\@State\n-   withAnimation wraps action that triggers recompute\n-   Must publish on main thread, use \\`.receive(on:)\\`\n-   BindableObject for external data, is a reference type, for existing\n    models\n\n<!-- -->\n\n-   Protocol has \\`didChange\\` property which must be a\n    Publisher/Subject\n-   Call .send on subject when updating the data\n\n<!-- -->\n\n-   \\@ObjectBinding var model: \\<BindableObject conform\\>\n-   \\@EnvironmentObject var model: \\<BindableObject conform\\>\n-   Environment is indirectly passed through the view hierarchy\n\n<!-- -->\n\n-   Used by accent color, text direction, dynamic type, Dark Mode &\n    Forms\n\n<!-- -->\n\n-   Example when to use \\@State: Button tracking the highlight state\n\nonReceive(\\<publisher\\>) { newCurrentTime in\n\nÂ  self.currentTime = newCurrentTime\n\n}\n\nOther talks:\n\n-   Combine\n-   Building Custom Views with SwiftUI\n\nDay 4, session 2, Introducing Combine & Advances in Foundation\n==============================================================\n\nI-Ting Tina Liu\n\n-   Ordered Collection Diffing: \\`Sequence.difference(from:)\\` generates\n    diff, \\`Sequence.applying(diff:)\\` performs patch\n-   ContiguousBytes protocol, means data is available as contiguous\n    bytes in memory\n-   Data.compressed(using:), with 4 algorithms\n-   RelativeDateTimeFormatter (2 weeks ago)\n-   ListFormatter.localizedString(byJoining:)\n-   OperationQueue, barriers & progress counting\n\nTony Parker, Combine\n\n-   A unified, declaraive API for processing values over time\n-   Request driven, vs Event driven\n-   Publishers/Subscribers/Operators\n-   Publishers are value type\n-   extension: NotificationCenter.Publisher(center: NotificationCenter,\n    name: Notification.Name, object: Any? = nil)\n-   Subscribers.Assign\n-   .receive(subscription:), .request(demand:), .receive(value:)\n-   Operators are also value types\n-   Example operator: Publishers.Map\n-   Declarative Operator API: functional, lists, error, threads, time\n\nDay 4, session 3, Advances in Networking part 1\n===============================================\n\n-   Low Data Mode\n-   Combine in URLSession\n-   WebSocket\n-   Mobility Improvements\n\nLow Power Mode:\n\n-   Per wifi/cellular network configurable\n-   System policy:\n\n<!-- -->\n\n-   Discretionary tasks deferred\n-   Background App Refresh disabled\n\n<!-- -->\n\n-   Application\n\n<!-- -->\n\n-   Reducing image quality\n-   Less pre-fetching\n-   Synchronize less often\n-   Mark tasks \"discretionary\"\n-   Disable auto-play\n-   You should not block user-initiated work\n\nCombine in URLSession\n\n-   DataTaskPublisher, similar to URLSession.dataTask()\n-   Compassable operators, just like you expect, like Rx\n\nWebSocket support in URLSession & Networking.framework\n\n-   URLSession.shared.webSocketTask(with: URL).resume()\n-   Stats are calculated including roundtrip time\n\nMobility\n\n-   WiFi-assist greatly improved\n-   Multipath-TCP now used in Maps & Music\n-   See[Â https://multipath-tcp.org](https://www.google.com/url?q=https://multipath-tcp.org&sa=D&ust=1559981348860000)\n\nDay 4, session 4, Combine in Practice\n=====================================\n\nMichael LeHew, Ben D. Jones\n\nSprak enorm voor zich. Standaard voorbeeld van RxSwift met zoekbalk.\nGekozen oplossing had debounce, districtUntilChanged alternatief, etc.\n\nDay 4, session 5, Natural Language processing\n=============================================\n\n-   NLGazetteer/MLGazetteer: bloom filter, results in Text Catalog\n-   Word Embeddings: vector representation of words\n-   Neural Networks in NLP framework\n\nDay 4, session 7, Text Recognition in the Vision Framework\n==========================================================\n\n-   Framework: Vision\n-   VNRecognizeTextRequest, does the heavy lifting for you!\n-   Sample code attached to session\n-   Two paths: fast (uses character recognition), accurate (uses NN to\n    recognize sentences)\n-   Fast: processing time, memory footprint\n-   Accurate: support for rotated, variety of fonts\n-   VMImageRequestHandler =\\> VNRecognizeTextRequest =\\> callback\n    VNRecognizedTextObservation\n-   VMRecognizeTextRequestRevision1 to pin down to the specific version\n    that you have optimized for\n-   Allows finding substrings in candidate results, which will return\n    the correct boundingbox!!!\n-   VisionKit, VNDocumentCameraViewController\n-   Language knowledge, performance, processing results\n-   Custom Lexicon support for domain specific language:\n    \\`VNRecognizeTextRequest.customWords = \\[\"1337\", \"q42\"\\]\\`\n-   \\`usesCPUOnly\\` allows for running specifically on CPU if GPU is in\n    use by game/AR/etc.\n-   Demo app \"My First Image Reader\" contains Continuity Camera support\n-   Don't take the main result for granted: the topCandidates are also\n    available. Use those for indexing too to increase recall!\n-   NSDataDetector, for types of interest (built in: Addresses, URLs,\n    dates & phone numbers, custom: Lexicon, RegExp)\n-   [developer.apple.com/wwdc19/234](https://www.google.com/url?q=http://developer.apple.com/wwdc19/234&sa=D&ust=1559981348864000)\n\nDay 4, session 8, Advance in Networking part 2\n==============================================\n\n-   Bonjour\n\n<!-- -->\n\n-   Wide-Area Service Discovery: discover printers in different network,\n    via \"Discovery Proxy\" \\@tomas\n    ([https://github.com/IETF-Hackathon/mDNSResponder](https://www.google.com/url?q=https://github.com/IETF-Hackathon/mDNSResponder&sa=D&ust=1559981348864000))\n-   NWBrowser is a new Bonjour service discovery helper\n-   TLS with symmetric keys using a passphrase & CryptoKit demo'd in the\n    TicTacToe application\n\n<!-- -->\n\n-   Building Framing Protocols\n\n<!-- -->\n\n-   You can now write Framing logic that runs in the Networking User\n    Thread\n-   Implement NWProtocolFramerImplementation, handleInput, handleOutput\n-   Add custom protocol to parameters.applicationProtocols\n\n<!-- -->\n\n-   Collecting Metrics\n\n<!-- -->\n\n-   URLSession Task Metrics is improved\n-   Available in didFinishCollectingMetrics call of URLSession\n-   Network.framework Metrics now allows inspecting metrics of\n    individual network calls\n-   'Optimistic DNS' optimistically connects to last known server of\n    DNS. In parallel performs a DNS lookup & disconnects initial\n-   Devices&Simulators now has Device Conditions (for example Network\n    Link which can be set to 3G, WiFi or High Latency DNS)\n\n<!-- -->\n\n-   Best Practices and Status Updates (by Stuart Cheshire)\n\n<!-- -->\n\n-   Catalyst apps have by default only access for Outgoing applications\n-   TLS 1.3 is now supported. Much faster (1 roundtrip instead of 2) and\n    more secure (AEDE & Forward Secrecy)\n-   Access to network information is now restricted to select apps,\n    current VPN apps & NEHotspotConfiguration apps\n-   Use the Network Link Conditioner in Xcode tool Devices&Simulators\n-   allowsExpensiveNetworkAccess, waitsForConnectivity = true\n-   file:// and ftp:// are no longer available\n-   SPDY is replaced by HTTP/2\n-   '\\_tcp.\\_tictactoe' Bonjour service is actually registered with IANA\n    ð¤£\n-   Apple team won the ACM award for great networking achievements for\n    multi-path TCP today\n\nDay 5, session 1, Building Custom Views in SwiftUI\n==================================================\n\nDave Abraham\n\nLayout System\n\n-   \"Layout is about determining the bounds of what you see on the\n    screen\"\n-   Root View -\\> Content View -\\> Text, root view is already minus the\n    safe area insets\n-   Modifier: '.edgesIgnoreingSafeArea(true)'\n-   Parent proposes size for a child, but child chooses its own size\n-   Modifiers: .aspectRatio(1), .frame(width: height:)\n-   SwiftUI rounds to nearest pixel\n-   .padding() uses adaptive padding, automatically resizes padding\n    depending on environment\n-   By default, Image's are fixed size\n-   Adaptive Spacing & Edge to Edge spacing adheres to Human Interface\n    Design Guidelines\n-   How Stacks work: walkthrough about how the child sizes are\n    calculated\n-   \\`.layoutPriority(1)\\`, default priority is 0. Children are examined\n    in layout priority order.\n-   Alignments include \\`.lastTextBaseline\\` which align all text\n    baselines to the bottom (ict .bottom)\n-   aligmentGuide(\\<.alignment\\>) { d in d\\[.bottom\\] \\* 0.98 }\n-   Custom 'AlignmentID' for deep nested subview alignment.\n\nCustom Views\n\n-   Demo code of creating a colorwheel\n-   Custom Shapes: adhere to Shape { func path(in rect: CGRect) -\\>\n    Path, optional var animatableData: AnimatableData }\n-   Modifier: .tapAction { ... }\n-   Custom Transisitions (scaleAndFade shown in demo)\n-   Uses ViewModifier { func body(content: Content) -\\> some View }\n-   let transition = AnyTransition.modifier(active: modifier identity:\n    modifier)\n-   drawingGroup() draws everything with Metal in CALayer\n\nDay 5, session 2, Core ML TuriCreate\n====================================\n\n-   Two new tasks: 1) One-Shot Object Detection task, 2) Drawing\n    Classification task\n-   Instead of having multiple images of the same class, One-Shot will\n    automatically augment a set of pictures with your classes single\n    training image\n-   Demo in Jupiter notebook\n-   turicreate.load\\_images(\"./\") loads all files in directory\n-   \"SFrame\" is a container for all your data\n-   turicreate.on\\_shot\\_object\\_detector.create(sframe, 'label') trains\n    & creates the ML model\n-   Super easy way to create a model for image recognition!!\n-   New input: Apple Pencil\n-   Build Drawing Classification model from SVG or images, and results\n    in \\<500kB on-device model for detecting Apple Pencil drawings\n-   Watch this video as a good primer, if you want to create an image\n    recognition app!\n-   Very handy \"Interactive Visualisation / Verification Explorer\" which\n    visualizes the results of the model training & verification\n\nDay 5, session 3, Creating ML Experiences\n=========================================\n\n-   \"Design more than just the interface\"\n-   Very high level talk about ML experiences, good watch for customers\n    wanting to use ML & for Interaction Designers\n-   Outputs: multiple options (all results from confidence list result),\n    attributes (how does the app decide?), confidence (how sure?),\n    limitations\n-   State real facts in attributions \"Top Picks, because you love\n    cooking\" =\\> \"Top Picks, because you downloaded NY Cooking\"\n-   Convert confidence levels into easy to understand information /\n    actions.\n-   Use 'ranges' for confidence effect (you'll arrive between\n    13:10-13:20)\n-   Coaching tips like with Animoji: \"Low Light\", \"Camera Covered\"\n-   Limitation with alternatives in macOS: \"Set a timer for 20 minutes.\"\n    \"Sorry, can't set a timer, how about a reminder?\"\n-   BasketBall ML app uses neat calibration setup: auto detects basket &\n    starts keeping the score\n-   Implicit Feedback, used in for example Siri Suggestions\n-   Explicit Feedback: buttons like/dislike are unclear what action will\n    follow. \"Show less from this Author\" is more specific.\n-   Corrections: fixing mistake, example in Keyboard. When you type a\n    name, correct the suggestion, then the Keyboard learns\n-   In Photos app, the auto-correct rotation & crop result will only be\n    the starting point of your action. You can then tweak it.\n\nDay 5, session 5, What's New in Core Bluetooth\n==============================================\n\n-   Bluetooth hardware/software:\n\n<!-- -->\n\n-   BR/EDR devices ('classic devices') support was missing in\n    CoreBluetooth, until now: this means CoreBluetooth can now talk to\n    Ã¡ll accessories, cars, etc.\n-   Physical layer rate goes from 1Mbps to 2Mbps with Bluetooth 5.0,\n    (available in iPhone 8+)\n-   Advertising Extensions means a larger advertisement payload can be\n    send (after smaller packet first)\n-   Extended Connections: wakes up the host processor only AFTER a BLE\n    connection handshake; requires support in accessory; less battery\n    drain\n-   Core Bluetooth abstracts over BR/EDR & BLE differences (BR/EDR\n    doesn't have GATT traditionally)\n-   Connection Event, send on matching connections!\n-   Dual-Mode Pairing: cross transport key derivation (BE 4.2 SIG spec),\n    same CBPeripheral, but both BLE and classic transport.\n-   Any LE connection can also be BR/EDR connected by iOS 13, etc (add\n    option in CB options).\n\n<!-- -->\n\n-   Privacy:\n\n<!-- -->\n\n-   Bluetooth access must be actively authorized for your app\n-   Apple Notification Center Service (ANCS), a GATT server service so\n    your accessory can show your iOS notifications\n-   \"Share System Notifications\" permission is required for ANCS\n\n<!-- -->\n\n-   Developer tools\n\n<!-- -->\n\n-   CB PacketLogger packet analysis application, visualizer. Decodes all\n    SIG & Apple protocols\n-   Live Capture: view packets between iOS \\<=\\> accessory on\n    PacketLogger running on Mac.\n-   Requires \"iOS Bluetooth developer logging profile\", app part of\n    \"Additional Tools for Xcode\"\n\nQuestions:\n\n-   Sending Heart Rate to other devices from Watch\n-   Overwrite outgoing message buffer?\n\nCore Bluetooth lab\n==================\n\n-   Can an Extended Runtime Watch application act as a Peripheral to a\n    Central accessory and send Heart Rate information?\n\n<!-- -->\n\n-   Contact information recorded, will contact\n\n<!-- -->\n\n-   Overwrite outgoing message buffer?\n\n<!-- -->\n\n-   Use advertisements instead\n\nDay 5, session 6, Siri Event Suggestions\n========================================\n\n-   Apps 'donate' events to Siri\n-   If your app supports \"Check-in\" you get a balloon on the home screen\n-   Intents.framework\n-   Donating: INInteraction(...)\n-   AppDelegate handler for Intent\n-   Donations that are updates of earlier items, and done in the\n    background will not trigger a donation notification\n-   Donate when the details are being shown, otherwise the Siri\n    notifications that happen with the donation seem out of context.\n-   Don't recommend watching: very slow very low information density,\n    instead just use documentation.\n"
  },
  {
    "name": "WWDCSessionNotesMathijs",
    "body": "WWDC Session Notes Mathijs\n\nDag 2 - Dinsdag\n---------------\n\nWhat's new in Xcode\n-------------------\n\nXcode now has Swift package manager integration, so you can use packages\nin your apps.\n\nUI improvements: you can add split views like in other editors. You can\nuse the canvas preview with SwiftUI.\n\nSF symbols are added, your own custom symbols are also possible, use an\nasset catalog.\n\nAssets in asset catalogs can now be Localized!\n\nYou can have asset colours and images vary for light/dark mode.\n\nUse the environment overrides button (in the debugger bar) to test dark\nmode and accessibility.\n\n### Conditions\n\nXcode now supports test plans. You can run tests for many different\nstates/configurations in one go.\n\n### Instruments\n\nNow has hierarchical tracks.\n\nYou can use os.signpostÂ to surface your own data in the debugger. For\nexample: measuring your networking code or JSON decoding (PostNL).\n\nUse UIViewRepresentable to use SwiftUI views in your existing UIKit\napps.\n\nCreating great localized experiences\n------------------------------------\n\n### Selecting languages\n\nNew iOS/macOS setting: change the language per app, independent of the\nsystem language\n\nÂ Â Â Â Â Â Â Â This means you no longer need a language picker inside the app\n\nÂ Â Â Â Â Â Â Â You can create a button that launches into settings\n\nÂ Â Â Â Â Â Â Â Use state restoration because the app gets relaunched\n\n### Workflow\n\nThe xcodebuild command can be used to import/export localizations\nautomatically or in your scripts.\n\nYou can use a stringsdictÂ for strings that vary by device class\n(example: tap here on iPhone/iPad vs. click here on a Mac).\n\n### Asset localization\n\nImages and symbol sets (new) can be localized right in the asset\ncatalog, just press the 'Localize' button!\n\n### Localized screenshots with XCTest\n\nXcode now supports test plans, this lets you run tests for multiple\ndifferent configurations at once.\n\nÂ Â Â Â Â Â Â Â Use accessibility identifiers to have your UI tests be\nindependent of the current language.\n\nÂ Â Â Â Â Â Â Â Settings for localization screenshots are under: UI Testing -\\>\nLocalization screenshots -\\> On\n\nQ: Is it useful to create a test suite just for taking app store\nscreenshots? These tests will just navigate through the right screens in\nthe app but not assert anything.\n\nSwift UI introduction - Creating your first app\n-----------------------------------------------\n\nThe SwiftUI view data structure gets compressed aggressively. So using\nsmall views to abstract things is fine and is encouraged.\n\nProperties of views are either a source of truthÂ (\\@State, \\@Binding) or\nderivedÂ from a source of truth (var, let).\n\nThere's live mode vs. Preview mode. Preview mode lets you inspect\ncomponents, tweak them and drag new ones in. Live mode runs the app as\nif it were in the simulator so you can interact with it.\n\nYou need the macOS Catalina beta to use previews at all.\n\n### State properties\n\nIn for example UIKit, the number of states and event orderings in your\nviews makes for a combinatorial explosion of different states. SwiftUI\ntries to remedy this problem. SwiftUI scales with your brain, virtually\neliminating UI inconsistencies.\n\niPad apps on the Mac\n--------------------\n\n\\<architecture picture of the OS'es\\>\n\nAl lower level frameworks between iPadOS and macOS are unified.\n\nOnly WebKit, SceneKit, Mapkit etc are copies that run on top of either\nAppKit or UIKit.\n\niPad apps on a Mac get a different bundle ID, prefixed with\n'uikitformac'\n\n.xcframeworkÂ packages multiple platform versions of a library/framework\nin a single bundle. Useful if you need to ship a binary.\n\nYou get a lot of functionality and \"Mac-likeness\" for free! That doesn't\nmean you don't have to do anything. Adopt a mac icon, menus, toolbars,\ntouch bar, hover events, help, etc.\n\nOther than that, differences between the platforms are subtle. Some\nframeworks are not available because they don't make sense (use hardware\nfeatures of iPhone/iPad) or aren't ported (yet). Some types of\nextensions are not available.\n\nIntroducing RealityKit & Reality composer\n-----------------------------------------\n\nReality Composer: 3D design application from Apple that lets you easily\ncreate AR and 3D worlds for use in your apps.\n\nRealityKit: Enhances ARKit with occlusion and more.\n\n------------------------------------------------------------------------\n\nDag 3 - Woensdag\n================\n\nSign in With Apple\n------------------\n\nPrivacy first. The user can choose what information they disclose.\nPossible to request a unique ID, Full name, and/or verified email\naddress.\n\nApple UX, super smooth. ðð¼\n\nÂ Â Â Â Â Â Â Â Available on all of Apple's platforms. Via web also on Windows\nand Android!\n\nUser can choose to hide their email address. In that case, you'll get a\nunique email from Apple private email relay system.\n\nUse the anti fraud bit to pick out suspected fake users.\n\n### How to\n\n1.  Add the entitlement\n2.  Associate your domain with the app\n\nASAuthorization\n\nPerform request: Apple ID or password autofill possible.\n\nÂ Â Â Â Â Â Â Â Is it possible to upgrade a user from username+password to Apple\nID?\n\nPerform an account check on launch. This call is very fast.\n\nÂ Â Â Â Â Â Â Â Sign a user in if they already have an account,\n\nÂ Â Â Â Â Â Â Â unlink in case they revoked.\n\nÂ Â Â Â Â Â Â Â show the sign in UI if they don't have an account.\n\n### Best practices\n\n-   Check for existing account on startup\n-   Use the real user indicator\n-   Use the button API to draw the button\n-   Implement on all your supported platforms\n\nImplementing dark mode on iOS\n-----------------------------\n\nInstead of hardcoded colours, use semantic colours.\n\nPrimary, secondary tertiary backgrounds and more are provided by apple.\nThey already made a design system that you can adopt. But you can define\nyour own colors using an asset catalog.\n\nOther than colors, there are materials, consisting of translucency on\ntop of a background.\n\nÂ Â Â Â Â Â Â Â New materials (blur effects) are in the SDK\n\nImplementing dark mode:\n\nÂ Â Â Â Â Â Â Â Specify dark mode background colors and images in your asset\ncatalog.\n\nResolving colours yourself\n\nResolve dynamic colours in layoutSubviews()\n\nListen to traitcollectiondidchange/tintcolordidchange for changes\n\nYou can always safely set the current trait collection, even on a\nbackground thread. If you do so, be consistent on which thread you do\nit.\n\n### Trait collections\n\nThere is not always one single trait collection in the app\n\nThe trait collection cascades downwards from\n\nUIScreen -\\> UIWindowScene -\\> UIWindow -\\> UIPresentationController -\\>\nUIViewController -\\> UIView\n\nTraits are predictedÂ during UIView initialisation\n\nYou can override the traitcollection for a viewcontroller/view using the\nproperty:\n\nÂ Â Â Â Â Â Â Â overrideUserInterfaceStyle\n\nÂ Â Â Â Â Â Â Â Q: so this does cascade downwards?\n\nSwiftUI essentials\n------------------\n\nA good UI requires much more than just a component system.\n\nIt/you should support:\n\n-   Accessibility\n-   Multiple windows\n-   Rich notifications\n-   Multiplatform\n-   Dark mode\n-   Size classes\n\nAlso you add your own unique features, design, delighters.\n\nSpend more time on the custom (and fun) stuff, less on the basic stuff.\n\nDeclarative vs. Imperative\n\nDollar sign -\\> gets a binding\n\nModifiers create a new view from an existing view\n\nÂ Â Â Â Â Â Â Â E.g. padding -\\> color vs. Color -\\> padding\n\nDon't worry about the performance impact, SwiftUI builds a highly\noptimised data structure\n\n'some View' lets the compiler infer the return type\n\nPrimitive views: text, color, spacer, image, shape, divider are the\nendpoint for the recursive view hierarchy.\n\nPush your if's inside modifiers \\[as a ternary\\] to help SwiftUI better\ndetect changes and provide animations\n\nThere's a Form component that can contain heterogeneous elements and\norder them into sections.\n\nButtons can change their look based on their container (VStack vs Form)\nand platform.\n\nAdvances in UI datasources\n--------------------------\n\nThe current state of the art: you have to create a UITableViewDataSource\nand tell the tableViewController about updates yourself. This often goes\nwrong, causing crashes (incorrect row count).\n\nIntroducing: Diffable data source. (UITableViewDiffableDataSource,\nUICollectionViewDiffableDataSource)\n\nInitialize this class with a closure that returns your cells. The\nclosure works similar to cellForRowAtIndexPath.\n\nDifferences in the data are calculated and animated automatically when\nyou call .apply()\n\nÂ Â Â Â Â Â Â Â Nb: Data items need to conform to hashable\n\nPerformance is currently good, and will improve in the future. But\ndiffing is a linear operation, O(n) complexity. You can call apply()\nfrom the background queue.\n\nOh, and it's a Swift only API!\n\nAdopting Swift PackagesÂ in Xcode\n--------------------------------\n\nXcode has SPM integration, yada yada. Booring.\n\nIf you document your sources using Swiftdoc comments, these docs will be\nvisible in the generated interface.\n\nThe xcshareddataÂ directory contains the version lock, so don't forget to\ncheck it in.\n\nYou can only have one version of a packageÂ in a workspace at a time.\n\nÂ Â Â Â Â Â Â Â It can cause resolution errors if your version requirements\ndiffer in the graph.\n\n------------------------------------------------------------------------\n\nDag 4 - Donderdag\n=================\n\nData flow through SwiftUI\n-------------------------\n\nBest practice: Create a single source of truthÂ that propagates downward!\n\n\\@StateÂ -\\> this value can change over time, and view depends on it\n\n-   Is view-local\n-   The frameworks allocates & manages your storage\n-   Mutation generates a new view body\n-   Uses a property wrapper\n-   Every \\@state is a source of truth\n-   Views are a function of state, not a sequence of events\n\nPublisher\n\n-   .onReceive(PodcastPlayer.currentTimePublisher) { self.stateVariable\n    = \\$0 }\n\nBindableObjectÂ (protocol)\n\n-   Use it to connect existing data/services to SwiftUI\n-   BindableObject is:\n\n<!-- -->\n\n-   External\n-   A reference\n-   Developer managed\n\nvar didChange = PassthroughSubject\\<Void, Never\\>()\n\ndidChange.send()\n\n\\@ObjectBindingÂ creates a dependencyÂ from the view upon the model\n\n-   You inject this dependency into the view\n-   Automatic dependency tracking\n-   Don't use this to pass models through the hierarchy, use\n    \\@EnvironmentObjectÂ instead\n\n\\@EnvironmentObject pushes data through the view hierarchy\n\nViews are a low-cost abstraction. Using a lot is encouraged.\n\n### How do I choose where this state belongs?\n\nCompare it to button. Button has internal state for its highlight when\nyour finger is on it. That state is truly owned by the button. If it's\nnot, see if you can lift the state up, for example to a bindable object.\n\nIntroducing Combine & advances in Foundation\n--------------------------------------------\n\n### What's new\n\n#### Diffing\n\nContiguousBytes\n\nlet compressed = try data.compressed(using: .lzfse)\n\nUnit conversions, new units\n\nRelativeDateTimeFormatter\n\n#### OperationQueue\n\nHas a high level API for doing work in sequence, and it now support\nprogress indication.\n\n#### Combine\n\nA unified declarative api for processing values over time\n\n##### Combine key concepts\n\nPublishers\n\nÂ Â Â Â Â Â Â Â Defines how values and errors are produced\n\nÂ Â Â Â Â Â Â Â Is a value type\n\nÂ Â Â Â Â Â Â Â Allows for registration of a subscriber\n\nÂ Â Â Â Â Â Â Â Example: \\`NotificationCenter.Publisher\\` publisher\n\nSubscribers\n\nÂ Â Â Â Â Â Â Â Counterpart to publisher\n\nÂ Â Â Â Â Â Â Â Receives values and a completion\n\nÂ Â Â Â Â Â Â Â Is a reference type\n\nÂ Â Â Â Â Â Â Â Example: \\`Subscribers.Assign\\` is a keypath subscriber\n\nOperator\n\nÂ Â Â Â Â Â Â Â Returns a new publisher\n\nÂ Â Â Â Â Â Â Â Changes values\n\nUse combine today\n\n1.  Compose small parts into custom publishers\n2.  Adopt incrementally\n3.  Add a PublisherÂ to a property with \\@Published\n4.  Compose callbacks and Publishers with Future\n\nIntegrating SwiftUI\n-------------------\n\n[![](images/image1.jpg)]{style=\"overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 288.00px;\"}\n\n### SwiftUI can be easily hosted in UIKit\n\n-   Use UIHostingController\n-   NSHostingController/NSHostingView\n-   Use \\@IBSegueAction + UIHostingController to push a segue to a\n    swiftui view\n\n### UIKit in SwiftUI is also possible\n\n-   UIViewRepresentable\n-   UIViewControllerRepresentable\n\nA Coordinator object can be used to wrap a binding to make target/action\nwork with UIKit views.\n\nIntegrating your data model\n\nBindableObject protocol -\\> var didChange: PublisherType\n\n\\@ObjectBinding var data\n\nPublishers\n\nYou can already get publishers from Apple out of:\n\n-   KVO\n-   Notifications\n-   URLSession\n\nPassthroughSubject\n\n[![](images/image2.jpg)]{style=\"overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 424.50px; height: 362.98px;\"}\n\nText recognition with the vision framework\n------------------------------------------\n\nYou can now perform OCR with the framework, which is powered using\nmachine learning built by Apple.\n\nChoose between fast (characters) vs. accurate (sentences, NLP). Fast is\nmeant for real time applications, accurate if you have more processing\ntime. Defer it to the background if possible.\n\nTips:\n\n-   Apply your own business validation logic to weed out invalid results\n    from the OCR. Example: if you want to recognize a phone number using\n    OCR, check the format. Check if you get the same result back several\n    times to better ensure it's valid.\n-   It's a good idea to combine multiple ML/Vision/AI techniques\n    together in a pipeline to improve your results.\n\nAdvances in networking part 2\n-----------------------------\n\nUse URLSession and Network.framework to get all the benefits of modern\nnetworking\n\nBonjour is now on all major platforms, including Windows and Android.\n\nWide area service discovery can be done using Discovery Proxy. For\nexample, a bonjour printer that's on a different network \\[segment\\].\n\nÂ Â Â Â Â Â Â Â Example\nimplementation:[Â ](https://www.google.com/url?q=http://github.com/ietf-hackathon/mdnsresponder&sa=D&ust=1559977671983000)[github.com/ietf-hackathon/mdnsresponder](https://www.google.com/url?q=http://github.com/ietf-hackathon/mdnsresponder&sa=D&ust=1559977671983000)\n\n------------------------------------------------------------------------\n\nDag 5 - Vrijdag\n===============\n\nCreating custom SwiftUI views\n-----------------------------\n\nTip:Â .edgesIgnoringSafeArea(.all)Â modifier to ignore safe area\n\nThe parent view proposes a size for its child, but a child view always\nchooses its own size, the parent cannot force that.\n\nNext, the parent places the child in the parent's coordinate space.\nCoordinates are rounded off to the nearest pixel.\n\n\"Focus on the things that make your app special.\" Also, avocado toast.\n\n.padding(\\[edges\\])Â gives you adaptive padding by default.\n\nModifiers always return a new view. So padding is a view.\n\nImages are fixed size unless you mark them as resizable\n\n.layoutPriority(n)\n\nDefining a new vertical alignment:\n\nÂ Â Â Â Â Â Â Â enum Foo: AlignmentID {\n\nÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â static func defaultValue...\n\nÂ Â Â Â Â Â Â Â }\n\n### Custom Views\n\nUse the Shape protocol, the only requirement is path(in rect:).\n\nImplement animatableData to animate it.\n\nZStack stacks views on top of each other.\n\nprotocol ViewModifier\n\nÂ Â Â Â Â Â Â Â Applies changes to another view\n\n.drawingGroup()Â flattens all the SwiftUI views in a single one and\nrenders it with metal. This only works if the child views are Shapes.\nFor UIKit controls it won't work.\n\nGreat developer habits\n----------------------\n\nProgramming takes craft, care & ingenuity. ð©ð¼âð» Build good habits to\nstay on track. Compare it to habits you've built for driving your car.\nYou automatically take care of many things without even realizing it.\n\n### Organize\n\nClean (virtual) workspace\n\n-   Organize functionally using groups that match the folder structure\n    on disk\n-   Storyboard references\n-   Modernize your project file\n-   File \\> Project settings \\> New build system\n\n### Track\n\nUse git.\n\n### Document\n\nWrite clear commit messages. Write useful comments.\n\n### Test\n\nUse unit tests for code that you could forget (example:\nserializing/deserializing), and is not covered by the type system. Use\nthem to test for regressions.\n\n### Analyze\n\n-   Use the network link conditioner\n-   Use the address sanitizer to check for buffer overflows\n-   Use thread sanitizer to check for race conditions\n-   Use the undefined behavior sanitizer\n\n### Evaluate\n\nUse code review.\n\n### Decouple\n\nSplit code up into packages/libraries/frameworks.\n\nCreating great ML experiences\n-----------------------------\n\nAll kinds of features use ML, such as the airpods, the keyboard,\nphotos\\...\n\nExample: photos categorizes the photos based on what's in them.\n\nIt takes more than just the \\[user\\] interface. Think about the\ninformation design.\n\nWe have to design the model and its interface.\n\n[![](images/image3.jpg)]{style=\"overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 370.00px; height: 439.66px;\"}\n\nEvaluation\n----------\n\n### Data\n\nLots of training data is crucial to get a good result.\n\nData needs to be designed.\n\nCollect data intentionally.Â Data biases are lurking. Example: for face\nrecognition, collect data of all races and types of users. For an app\nthat's used outdoors, collect data from outdoors.\n\nOptimize for the customers you want. Don't reflect the world, but create\nfor the world how you want it to be.\n\nTest your app for biases.\n\nUpdate data as product specifications change.\n\nBeware of standard (academic) data sets, as these often don't represent\nreal experiences.\n\n### Metrics\n\nEvaluate your model. Design metrics to evaluate it. The metrics should\ndefine if an experience is good. Your metrics reflect your values.\n\nInform users about the metrics, for example in Face ID: 1 in 1000000\nchance of a stranger unlocking your device. Give it meaning to them.\n\nInterface patterns\n------------------\n\n### Outputs\n\n-   Multiple options\n\n<!-- -->\n\n-   Choose from the results a feature generates\n-   Provide a set of meaningfully different options, such as different\n    routes in a navigation app.\n\n<!-- -->\n\n-   Attributions\n\n<!-- -->\n\n-   Avoid profiling people\n-   State real facts, instead of \"Top picks because you love cooking\",\n    say \"Top picks because you love \\$appName\"\n-   Cite the data source\n\n<!-- -->\n\n-   Confidence -\\> certainty measure\n\n<!-- -->\n\n-   Translate into human terms instead of displaying just raw\n    numbers/percentages\n-   Provide a range in case of an estimation\n-   \n\n<!-- -->\n\n-   Limitations\n\n<!-- -->\n\n-   Limitations happen when there's a mismatch between people's mental\n    model of the feature and of what the feature actually does.\n-   Guide people past limitations. Example: memoji. A tip is shown when\n    there's too little light or the sensor is covered.\n-   Manage expectations. Suggest alternative actions if something is\n    impossible.\n\nOutputs are a design medium.\n\n### Inputs\n\n-   Calibration\n\n<!-- -->\n\n-   User provides essential information to make the feature work.\n-   Be quick and effortless, only ask for essential information\n-   Introduce, guide and confirm\n-   Provide a way to update/remove the information\n\n<!-- -->\n\n-   Implicit feedback\n\n<!-- -->\n\n-   Improve the model based on interactions with the app.\n-   Strive to identify people's intention\n-   Accuracy over speed\n-   Respect people's privacy\n-   Make interactions more accurate and delightful\n\n<!-- -->\n\n-   Explicit feedback\n\n<!-- -->\n\n-   Prioritize negative feedback over positive.\n-   Love/dislike? Clearly describe the action and its consequences.\n    Provide different options to better understand the user's intention.\n\n<!-- -->\n\n-   Corrections\n\n<!-- -->\n\n-   Detect when the user fixes a mistake and update the model.\n-   Use known tasks for this. For example, with spelling, the standard\n    text editing is recognized and used.\n-   Example: cropping in photos suggests a crop and allows the user to\n    tweak it.\n\nWhen we align the way we create with the values we uphold we can create\ngreat experiences.\n\nGetting the most out of multitasking \\[on iPad\\]\n------------------------------------------------\n\n### Architecting for multiple windows\n\n#### AppDelegate\n\ndidFinishLaunchingÂ contains one time setup, and creates the initial user\ninterface\n\nThis pattern is invalid now, apps have a SceneDelegate which is\nresponsible for UI.\n\nAppDelegate is responsible for process lifecycle.\n\nAdopt SceneDelegate and UIKit will stop calling app delegate UI methods.\n\n#### State restoration\n\n#### Keeping scenes in sync\n\nWhen you have multiple windows, you can have multiple instances of the\nsame viewController. Make sure that when you make a change in one, the\nother will update with the changes.\n\nrequestSceneSessionActivationÂ API opens a new window.\n\nDesigning and building great shortcuts\n--------------------------------------\n\nCreate an overview of the features/activities of your app. Determine\nwhat actions are valuable to do by voice.\n\nGood shortcuts are repeatable, don't rely on visuals or tapping and are\ninvocable in most context.\n\nApple provides an \"Add to Siri\" button. Use this in a focused context,\nwhen you suspect the user will want to do an action again some time.\n\nKeep the activation phrase as short as possible. \"Get the 35 bus\nschedule\" -\\> \"Bus schedule\"\n\n### Designing Siri interactions\n\nKeep dialogue short and concise.\n\n#### Summary\n\nShortcuts elevate your app's most repeatableÂ features.\n\nUse the add to siri button.\n"
  },
  {
    "name": "wwdc2019-237",
    "body": "Dave Abraham & John Harper\n\nLayout System\n- âLayout is about determining the bounds of what you see on the screenâ\n- Root View -> Content View -> Text, root view is already minus the safe area insets\n- Modifier: `.edgesIgnoreingSafeArea(true)`\n- Parent proposes size for a child, but child chooses its own size\n- Modifiers: `.aspectRatio(1)`, `.frame(width: height:)`\n- SwiftUI rounds to nearest pixel\n- `.padding()` uses adaptive padding, automatically resizes padding depending on environment\n- By default, Imageâs are fixed size\n- Adaptive Spacing & Edge to Edge spacing adheres to Human Interface Design Guidelines\n- How Stacks work: walkthrough about how the child sizes are calculated\n- `.layoutPriority(1)`, default priority is 0. Children are examined in layout priority order.\n- Alignments include `.lastTextBaseline` which align all text baselines to the bottom (ict `.bottom`)\n- `aligmentGuide(<.alignment>) { d in d[.bottom] * 0.98 }`\n- Custom âAlignmentIDâ for deep nested subview alignment.\n\nCustom Views\n- Demo code of creating a colorwheel\n- Custom Shapes: adhere to `Shape { func path(in rect: CGRect) -> Path, optional var animatableData: AnimatableData }`\n- Modifier: `.tapAction { â¦ }`\n- Custom Transisitions (scaleAndFade shown in demo)\n- Uses `ViewModifier { func body(content: Content) -> some View }`\n- `let transition = AnyTransition.modifier(active: modifier identity: modifier)`\n- `.drawingGroup()` draws everything with Metal on GPU in CALayer\n"
  },
  {
    "name": "wwdc2019-239",
    "body": "\nProgramming takes craft, care & ingenuity. ð©ð¼âð» Build good habits to\nstay on track. Compare it to habits you've built for driving your car.\nYou automatically take care of many things without even realizing it.\n\n### Organize\n\nClean (virtual) workspace\n\n-   Organize functionally using groups that match the folder structure\n    on disk\n-   Storyboard references\n-   Modernize your project file\n-   File \\> Project settings \\> New build system\n\n### Track\n\nUse git.\n\n### Document\n\nWrite clear commit messages. Write useful comments.\n\n### Test\n\nUse unit tests for code that you could forget (example:\nserializing/deserializing), and is not covered by the type system. Use\nthem to test for regressions.\n\n### Analyze\n\n-   Use the network link conditioner\n-   Use the address sanitizer to check for buffer overflows\n-   Use thread sanitizer to check for race conditions\n-   Use the undefined behavior sanitizer\n\n### Evaluate\n\nUse code review.\n\n### Decouple\n\nSplit code up into packages/libraries/frameworks."
  },
  {
    "name": "wwdc2019-401",
    "body": "\nXcode now has Swift package manager integration, so you can use packages\nin your apps.\n\nUI improvements: you can add split views like in other editors. You can\nuse the canvas preview with SwiftUI.\n\nSF symbols are added, your own custom symbols are also possible, use an\nasset catalog.\n\nAssets in asset catalogs can now be Localized!\n\nYou can have asset colours and images vary for light/dark mode.\n\nUse the environment overrides button (in the debugger bar) to test dark\nmode and accessibility.\n\n### Conditions\n\nXcode now supports test plans. You can run tests for many different\nstates/configurations in one go.\n\n### Instruments\n\nNow has hierarchical tracks.\n\nYou can use os.signpostÂ to surface your own data in the debugger. For\nexample: measuring your networking code or JSON decoding (PostNL).\n\nUse UIViewRepresentable to use SwiftUI views in your existing UIKit\napps."
  }
]